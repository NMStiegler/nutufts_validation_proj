{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to voxelize and save all 20 of the simulated events in the /tutorial_files/dlmerged_larflowtruth_mcc9_v13_bnbnue_corsika_run00001_subrun00001.root file.\n",
    "\n",
    "Modified from ~/icdl/notebooks/tutorials/tutorial_make_truthlabeled_spacepoints_and_voxels.ipynb tutorial written by Taritree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import useful packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import plotly as pl\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.24/06\n"
     ]
    }
   ],
   "source": [
    "# on trex, for some reason, need to load ROOT in separate cell before loading icdl modules\n",
    "import ROOT as rt\n",
    "from ROOT import std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from larlite import larlite\n",
    "from larlite import larutil\n",
    "from larcv import larcv\n",
    "from ublarcvapp import ublarcvapp\n",
    "from larflow import larflow\n",
    "import lardly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data file\n",
    "Below we specify the location of the file we want to use with\n",
    "* simulated data from the detector (the three wire plane images)\n",
    "* truth information we can use to label generated spacepoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify location of the file we want to open\n",
    "inputfile = \"/tutorial_files/dlmerged_larflowtruth_mcc9_v13_bnbnue_corsika_run00001_subrun00001.root\"\n",
    "\n",
    "# we need the name of the TTree that stores our images\n",
    "WIRE_ADC = \"wire\"\n",
    "\n",
    "# Use ROOT to open the file\n",
    "rfile = rt.TFile(inputfile,\"open\")\n",
    "# rfile.ls() # To show the contents of the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries in file:  20\n",
      "\u001b[95m    [NORMAL]  \u001b[0m\u001b[95m<open> \u001b[0mOpening a file in READ mode: /tutorial_files/dlmerged_larflowtruth_mcc9_v13_bnbnue_corsika_run00001_subrun00001.root\n",
      "    \u001b[95m[NORMAL]\u001b[00m \u001b[0m \u001b[94m<larcv::prepare_input>\u001b[00m Opening a file in READ mode: /tutorial_files/dlmerged_larflowtruth_mcc9_v13_bnbnue_corsika_run00001_subrun00001.root\n",
      "    \u001b[95m[NORMAL]\u001b[00m \u001b[0m \u001b[94m<larcv::initialize>\u001b[00m Prepared input with 20 entries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in <TChain::SetBranchAddress>: The pointer type given (larlite::event_base) does not correspond to the class needed (larcv::EventChStatus) by the branch: chstatus_wire_branch\n",
      "Error in <TChain::SetBranchAddress>: The pointer type given (larlite::event_base) does not correspond to the class needed (larcv::EventChStatus) by the branch: chstatus_wiremc_branch\n"
     ]
    }
   ],
   "source": [
    "ioll = larlite.storage_manager( larlite.storage_manager.kREAD )\n",
    "ioll.add_in_filename(  inputfile )\n",
    "ioll.open()\n",
    "iolcv = larcv.IOManager( larcv.IOManager.kREAD, \"larcv\", larcv.IOManager.kTickBackward ) # we use kTickBackward to make it work\n",
    "iolcv.add_in_file( inputfile )\n",
    "iolcv.reverse_all_products() # Since we read in backwards\n",
    "iolcv.initialize()\n",
    "\n",
    "NENTRIES = iolcv.get_n_entries()\n",
    "print(\"Number of entries in file: \",NENTRIES)\n",
    "assert(NENTRIES == 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set the Detector Geometry\n",
    "\n",
    "To calculate wire intersection points, we need the geometry of the detector.\n",
    "\n",
    "To speed up spacepoint proposal generation, we actually do not calculate wire-intersections at runtime.\n",
    "Instead we pre-calculate which wires intersect with which and store these in detector-specific \"overlap matrix\" files.\n",
    "\n",
    "These overlap files are generated by code in `icdl/spacepointgen`.\n",
    "\n",
    "However, DON'T remake these. You can ask someone for these files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found overlap matrix file\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DETECTOR = \"uboone\"\n",
    "\n",
    "# choices: \"icarus\", \"uboone\", \"sbnd\"\n",
    "overlap_folder = \"/tutorial_files/\"\n",
    "\n",
    "if DETECTOR == \"icarus\":\n",
    "    detid = larlite.geo.kICARUS\n",
    "    overlap_matrix_file = overlap_folder+\"/output_icarus_wireoverlap_matrices.root\"\n",
    "elif DETECTOR == \"uboone\":\n",
    "    detid = larlite.geo.kMicroBooNE\n",
    "    overlap_matrix_file = overlap_folder+\"/output_microboone_wireoverlap_matrices.root\"\n",
    "elif DETECTOR == \"sbnd\":\n",
    "    detid = larlite.geo.kSBND\n",
    "    overlap_matrix_file = \"does_not_exist_yet.root\"\n",
    "    \n",
    "if not os.path.exists(overlap_matrix_file):\n",
    "    print(\"WARNING: Could not find overlap matrices\")\n",
    "else:\n",
    "    print(\"Found overlap matrix file\")\n",
    "    \n",
    "larutil.LArUtilConfig.SetDetector(detid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the output file & algorithm objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[95m    [NORMAL]  \u001b[0m\u001b[95m<ReadTree> \u001b[0mLoading geo data for DetID=2 ...\n",
      " file=/home/nstieg01/icdl/larlite/larlite//LArUtil/dat/microboone_larlite_geodata.root \n",
      "\u001b[95m    [NORMAL]  \u001b[0m\u001b[95m<LoadData> \u001b[0m max channel numbers: 8255\n",
      "\u001b[95m    [NORMAL]  \u001b[0m\u001b[95m<LoadData> \u001b[0m geometry loaded successfully.\n",
      "\u001b[95m    [NORMAL]  \u001b[0m\u001b[95m<LoadData> \u001b[0mLoading data for DetectorProperties...\n",
      "     file=/home/nstieg01/icdl/larlite/larlite//LArUtil/dat/larutil_microboone.root \n",
      "old fXTicksOffsets branch used for MicroBooNE\n",
      "SimChannelVoxelizer: tickmin=2400 tickmax=8448  dtick=1\n",
      "\u001b[95m    [NORMAL]  \u001b[0m\u001b[95m<LoadData> \u001b[0mLoading data for LArProperties...\n",
      "     file=/home/nstieg01/icdl/larlite/larlite//LArUtil/dat/larutil_microboone.root \n",
      "old fEfield branch used for MicroBooNE\n",
      "SimChannelVoxelizer: tickmin=2400 tickmax=8448  dtick=6\n",
      "[VoxelizeTriplets::_define_voxels.L80] \n",
      " CRYO[0] TPC[0] \n",
      " NVOXELS: (1009,781,3457)\n",
      " VOXEL LENGTH: (6,0.3,0.3)\n",
      " BOUNDS: [2400,8454] [-116.03,118.27] [0,1037.1] \n"
     ]
    }
   ],
   "source": [
    "# Safeguard\n",
    "try:\n",
    "    outfile.Close()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# We are going to define a ROOT file for the algorithms to write out to\n",
    "outfilename = \"20spacepointTutorialData.root\"\n",
    "outfile = rt.TFile(outfilename,\"recreate\")\n",
    "triptree = rt.TTree(\"larmatchtriplet\",\"LArMatch triplets\") # a new tree to store triplet data\n",
    "\n",
    "# triplet proposal maker      \n",
    "tripletmaker = larflow.prep.PrepMatchTriplets()\n",
    "tripletmaker.set_wireoverlap_filepath( overlap_matrix_file  )\n",
    "ev_tripdata = std.vector(\"larflow::prep::MatchTriplets\")() # container to store triplet maker output\n",
    "triptree.Branch(\"triplet_v\",ev_tripdata) # add the container to the triplet tree, triptree\n",
    "\n",
    "# Keypoint maker\n",
    "kpana = larflow.keypoints.PrepKeypointData()\n",
    "#kpana.set_verbosity( larcv.msg.kDEBUG )\n",
    "kpana.setADCimageTreeName( WIRE_ADC )\n",
    "outfile.cd()\n",
    "kpana.defineAnaTree()\n",
    "\n",
    "# ssnet label data: provides particle label for each spacepoint                                                                                                                                                                          \n",
    "ssnet = larflow.prep.PrepSSNetTriplet()\n",
    "outfile.cd()\n",
    "ssnet.defineAnaTree()\n",
    "\n",
    "# We make spacepoints from 2D information, so there are some mistakes we fix using various methods\n",
    "truthfixer = larflow.prep.TripletTruthFixer()\n",
    "\n",
    "# Voxelizer:\n",
    "# The Voxelizer Class\n",
    "# See larflow/larflow/Voxelizer/VoxelizeTriplets.h for more info\n",
    "# \n",
    "voxelizer = larflow.voxelizer.VoxelizeTriplets()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run algorithms on x <= 20 events, creating spacepoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now running on entry: 0\n",
      "1\n",
      "    \u001b[95m[NORMAL]\u001b[00m \u001b[0m \u001b[94m<PrepMatchTriplets::process>\u001b[00m Have bad channel info make badchannel images\n",
      "    \u001b[95m[NORMAL]\u001b[00m \u001b[0m \u001b[94m<PrepMatchTriplets::process>\u001b[00m Store adc_v image[0] for (plane,tpc,cryo)=(0,0,0)\n",
      "    \u001b[95m[NORMAL]\u001b[00m \u001b[0m \u001b[94m<PrepMatchTriplets::process>\u001b[00m Store adc_v image[1] for (plane,tpc,cryo)=(1,0,0)\n",
      "    \u001b[95m[NORMAL]\u001b[00m \u001b[0m \u001b[94m<PrepMatchTriplets::process>\u001b[00m Store adc_v image[2] for (plane,tpc,cryo)=(2,0,0)\n",
      "[FlowTriples] plane[0] has 8533 (above threshold) pixels\n",
      "[FlowTriples] plane[1] has 11321 (above threshold) pixels\n",
      "[FlowTriples] plane[2] has 7506 (above threshold) pixels\n",
      "    \u001b[95m[NORMAL]\u001b[00m \u001b[0m \u001b[94m<PrepMatchTriplets::process_tpc_v2>\u001b[00m made total of 331477 nrepeated=91718 unique index triplets. time elapsed=4.80681\n",
      "    \u001b[95m[NORMAL]\u001b[00m \u001b[0m \u001b[94m<PrepMatchTriplets::make_truth_vector>\u001b[00m  (cryo,tpcid)=0,0) num larflow truth images=6\n",
      "    \u001b[95m[NORMAL]\u001b[00m \u001b[0m \u001b[94m<PrepMatchTriplets::make_truth_vector>\u001b[00m === (cryoid,tpcid)=(0,0) =======\n",
      "    \u001b[95m[NORMAL]\u001b[00m \u001b[0m \u001b[94m<PrepMatchTriplets::make_truth_vector>\u001b[00m  number of triplets: 331477\n",
      "    \u001b[95m[NORMAL]\u001b[00m \u001b[0m \u001b[94m<PrepMatchTriplets::make_truth_vector>\u001b[00m   number of sparse pixels: [ 15864, 13464, 13131 ]\n",
      "    \u001b[95m[NORMAL]\u001b[00m \u001b[0m \u001b[94m<PrepMatchTriplets::make_truth_vector>\u001b[00m   number of true-match triplets: 70247\n",
      "    \u001b[95m[NORMAL]\u001b[00m \u001b[0m \u001b[94m<PrepMatchTriplets::make_truth_vector>\u001b[00m   doublet truth: [ 52500, 53126, 61235, 62243, 42500, 42685, ]\n",
      "    \u001b[95m[NORMAL]\u001b[00m \u001b[0m \u001b[94m<PrepMatchTriplets::make_instanceid_vector>\u001b[00m === (cryoid,tpcid)=(0,0) =======\n",
      "    \u001b[95m[NORMAL]\u001b[00m \u001b[0m \u001b[94m<PrepMatchTriplets::make_instanceid_vector>\u001b[00m   number labeled: 70247 of 331477\n",
      "    \u001b[95m[NORMAL]\u001b[00m \u001b[0m \u001b[94m<PrepMatchTriplets::make_ancestorid_vector>\u001b[00m === (cryoid,tpcid)=(0,0) =======\n",
      "    \u001b[95m[NORMAL]\u001b[00m \u001b[0m \u001b[94m<PrepMatchTriplets::make_ancestorid_vector>\u001b[00m   number labeled: 65578 of 331477 total  and 70247true\n",
      "    \u001b[95m[NORMAL]\u001b[00m \u001b[0m \u001b[94m<PrepMatchTriplets::make_segmentid_vector>\u001b[00m === (cryoid,tpcid)=(0,0) =======\n",
      "    \u001b[95m[NORMAL]\u001b[00m \u001b[0m \u001b[94m<PrepMatchTriplets::make_segmentid_vector>\u001b[00m   number labeled: 67588 of 331477\n",
      "    \u001b[95m[NORMAL]\u001b[00m \u001b[0m \u001b[94m<PrepMatchTriplets::make_origin_vector_frommcreco>\u001b[00m === (cryoid,tpcid)=(0,0) =======\n",
      "    \u001b[95m[NORMAL]\u001b[00m \u001b[0m \u001b[94m<PrepMatchTriplets::make_origin_vector_frommcreco>\u001b[00m   number labeled: 57646 of 331477\n",
      "    \u001b[95m[NORMAL]\u001b[00m \u001b[0m \u001b[94m<TripletTruthFixer::_label_cosmic_pid>\u001b[00m === (cryoid,tpcid)=(0,0) =======\n",
      "    \u001b[95m[NORMAL]\u001b[00m \u001b[0m \u001b[94m<TripletTruthFixer::_label_cosmic_pid>\u001b[00m   number of cosmic-relables: 63673\n",
      "[TripletTruthFixer::_reassignSmallTrackClusters] num reassigned = 0\n",
      "[TripletTruthFixer::_merge_shower_fragments.L406] ShoweIinfo_t[0] pid=-11 tid=1012915 origin=1 vtx=(125.593,102.273,964.569)   matched cluster index: 0\n",
      "[TripletTruthFixer::_trueshowers_absorb_clusters.L593] merge fragments to 1 mcshower objects\n",
      "[TripletTruthFixer::_trueshowers_absorb_clusters.L609]  add shower fragment for trunk\n",
      "converter SCE: 0xaec0640\n",
      "TripletTruthFixer::converted 478 hits out of 70247 near vertex pixels\n",
      "[PrepKeypointData Inputs]\n",
      "  adc images: 3\n",
      "  badch images: 3\n",
      "  segment images: 3\n",
      "  instance images: 3\n",
      "  ancestor images: 3\n",
      "  mctracks: 105\n",
      "  mcshowers: 129\n",
      "  mctruths: 1\n",
      "static std::vector<int> ublarcvapp::UBWireTool::getProjectedImagePixel(const std::vector<float>&, const larcv::ImageMeta&, int, float) plane=2 wire=-0.0705304<-1.5\n",
      "Calculated SCE offsets\n"
     ]
    }
   ],
   "source": [
    "# Loop over 20 entries in original file to turn them all into spacepoints\n",
    "# for i in range(0, 20):\n",
    "# NUM_TO_DO = 1\n",
    "# for i in range (0, NUM_TO_DO):\n",
    "for i in range (0, 1):\n",
    "\n",
    "    print(f\"Now running on entry: {i}\")\n",
    "    # Now we load an event\n",
    "    ENTRY_NUM = i\n",
    "    \n",
    "    ioll.go_to(ENTRY_NUM)\n",
    "    \n",
    "    iolcv.read_entry(ENTRY_NUM)\n",
    "    \n",
    "    # Run the algorithms\n",
    "\n",
    "\n",
    "    # mcpg = ublarcvapp.mctools.MCPixelPGraph()\n",
    "    # mcpg.buildgraphonly( ioll )\n",
    "    # mcpg.printGraph(0,False)\n",
    "    # sys.stdout.flush()\n",
    "    outfile.cd()\n",
    "    \n",
    "    # Test\n",
    "    # tripletmaker = larflow.prep.PrepMatchTriplets()\n",
    "    # tripletmaker.set_wireoverlap_filepath( overlap_matrix_file  )\n",
    "    # ev_tripdata = std.vector(\"larflow::prep::MatchTriplets\")() # container to store triplet maker output\n",
    "    # triptree.Branch(\"triplet_v\",ev_tripdata) # add the container to the triplet tree, triptree\n",
    "    \n",
    "    # make triplet proposals: function valid for simulation or real data                                                                                                                                                                  \n",
    "    tripletmaker.process( iolcv, WIRE_ADC, WIRE_ADC, 10.0, True )\n",
    "\n",
    "    # make good/bad triplet ground truth                                                                                                                                                      \n",
    "    tripletmaker.process_truth_labels( iolcv, ioll, WIRE_ADC )\n",
    "\n",
    "    # fix up some labels\n",
    "    truthfixer.calc_reassignments( tripletmaker, iolcv, ioll )\n",
    "\n",
    "    # # make keypoint score ground truth                                                                                                                                                        \n",
    "    kpana.process( iolcv, ioll )\n",
    "    kpana.make_proposal_labels( tripletmaker )\n",
    "    kpana.fillAnaTree()\n",
    "\n",
    "    # # make ssnet ground truth                                                                                                                                                                 \n",
    "    ssnet.make_ssnet_labels( iolcv, ioll, tripletmaker )\n",
    "    \n",
    "    # i = 0\n",
    "    for imatch in range(tripletmaker._match_triplet_v.size()):\n",
    "        ev_tripdata.push_back( tripletmaker._match_triplet_v.at(imatch) )\n",
    "    #     i += 1\n",
    "    \n",
    "    # print(i)\n",
    "    \n",
    "    print(ev_tripdata.size())\n",
    "    triptree.Fill()\n",
    "    \n",
    "    # iolcv.clear()\n",
    "    # tripletmaker.clear()\n",
    "    \n",
    "\n",
    "outfile.cd()\n",
    "# write the data to file and then close the file\n",
    "kpana.writeAnaTree()\n",
    "ssnet.writeAnaTree()\n",
    "triptree.Write()\n",
    "outfile.Close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load x <= 20 entries & voxelize them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in <TChain::LoadTree>: Cannot find tree with name LArbysMCTree in file 20spacepointTutorialData.root\n"
     ]
    }
   ],
   "source": [
    "# Our plotting tools -- and the deep learning frameworks work with numpy arrays.\n",
    "# We have written C++ functions that output the spacepoints and labels we've generated into\n",
    "#  such numpy arrays\n",
    "from ctypes import c_int\n",
    "from larflow import larflow\n",
    "larflow.keypoints.LoaderKeypointData\n",
    "\n",
    "f_v = std.vector(\"std::string\")()\n",
    "f_v.push_back(outfilename)\n",
    "kploader = larflow.keypoints.LoaderKeypointData( f_v )\n",
    "kploader.set_verbosity( larcv.msg.kDEBUG )\n",
    "kploader.exclude_false_triplets( False )\n",
    "kploader.GetEntries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first make a VoxelSet, this is a container that holds the description of the active voxels \n",
    "from larcv import larcv\n",
    "\n",
    "# translation from how we label particle types to how lartpc_mlreco3d labeled particles\n",
    "# mlreco particle labels found in lartpc_mlreco3d/mlreco/utils/groups.py\n",
    "# larflow particle labels found in larflow/larflow/PrepFlowMatchData/PrepSSNetTriplet.h\n",
    "larcv2mlreco = {0:5, # bg -> ghost\n",
    "                1:1, # electron -> electron\n",
    "                2:0, # photon -> photon\n",
    "                3:2, # muon -> muon \n",
    "                4:3, # pion -> pion\n",
    "                5:4, # proton -> proton\n",
    "                6:3, # other (usually mesons) -> pion\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading entry 0\n",
      "KeypointLoader returned dictionary with event data. KEYS: \n",
      "dict_keys(['matchtriplet', 'match_weight', 'positive_indices', 'ssnet_label', 'ssnet_top_weight', 'ssnet_class_weight', 'kplabel', 'kplabel_weight', 'spacepoint_t', 'truetriplet_t', 'segment_t', 'truespan_t'])\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'VoxelizeTriplets' object has no attribute 'get_nvoxels'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-e8376e7515cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;31m# each voxel needs an ID number. We use the unrolled array position\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;31m# to calculate this, we need array strides for each dimension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     strides = [ voxelizer.get_nvoxels()[0]*voxelizer.get_nvoxels()[1],\n\u001b[0m\u001b[1;32m     73\u001b[0m                 \u001b[0mvoxelizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_nvoxels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m                 1]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'VoxelizeTriplets' object has no attribute 'get_nvoxels'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      \u001b[92m[INFO]\u001b[00m \u001b[0m \u001b[94m<LoaderKeypointData::load_entry::L126>\u001b[00m Loaded trees (ttriplet,tssnet,tkeypoint)\n",
      "[MatchTriplets::make_spacepoint_charge_array] number of true points: 70247 of 331477\n",
      "     \u001b[94m[DEBUG]\u001b[00m \u001b[0m \u001b[94m<LoaderKeypointData::sample_data>\u001b[00m LoaderKeypointData.cxx::L179 make triplets (cryo,tpcid)=(0,0)\n",
      "     \u001b[94m[DEBUG]\u001b[00m \u001b[0m \u001b[94m<LoaderKeypointData::sample_data>\u001b[00m LoaderKeypointData.cxx::L214  npos=70247 nneg=261230\n",
      "     \u001b[94m[DEBUG]\u001b[00m \u001b[0m \u001b[94m<LoaderKeypointData::sample_data>\u001b[00m LoaderKeypointData.cxx::L242 call make_ssnet_arrays\n",
      "     \u001b[94m[DEBUG]\u001b[00m \u001b[0m \u001b[94m<LoaderKeypointData::make_ssnet_arrays>\u001b[00m LoaderKeypointData.cxx::L333 pos_match_index=70247 withtruth=1 num_max_samples=331477\n",
      "     \u001b[94m[DEBUG]\u001b[00m \u001b[0m \u001b[94m<LoaderKeypointData::make_ssnet_arrays>\u001b[00m LoaderKeypointData.cxx::L356 make class labels and topological weight arrays. nelems=331477\n",
      "     \u001b[94m[DEBUG]\u001b[00m \u001b[0m \u001b[94m<LoaderKeypointData::make_ssnet_arrays>\u001b[00m LoaderKeypointData.cxx::L401 make class balancing weights\n",
      "     \u001b[94m[DEBUG]\u001b[00m \u001b[0m \u001b[94m<LoaderKeypointData::make_ssnet_arrays>\u001b[00m LoaderKeypointData.cxx::L429 Num bad labels: 0\n"
     ]
    }
   ],
   "source": [
    "# create an output file\n",
    "voxel_outfile_name = \"20_voxelized_tutorial_data.root\"\n",
    "out_larcv = larcv.IOManager( larcv.IOManager.kWRITE, \"voxeldata\" )\n",
    "out_larcv.set_out_file( voxel_outfile_name )\n",
    "out_larcv.initialize()\n",
    "\n",
    "for i in range(0, 1):\n",
    "\n",
    "    print(f\"Loading entry {i}\")\n",
    "    \n",
    "#     kploader = larflow.keypoints.LoaderKeypointData( f_v )\n",
    "#     kploader.set_verbosity( larcv.msg.kDEBUG )\n",
    "#     kploader.exclude_false_triplets( False )\n",
    "    \n",
    "    kploader.load_entry(i)\n",
    "\n",
    "    # the original image data in sparse2D array form\n",
    "    tripletmaker = kploader.triplet_v.at(0).setShuffleWhenSampling( False )\n",
    "    # print(tripletmaker)\n",
    "\n",
    "    # 2d images                                                                                                                                                                               \n",
    "    wireimg_dict = {}\n",
    "    for p in range(3):\n",
    "        wireimg = kploader.triplet_v.at(0).make_sparse_image( p )\n",
    "        wireimg_coord = wireimg[:,:2].astype(np.long)\n",
    "        wireimg_feat  = wireimg[:,2]\n",
    "        wireimg_dict[\"wireimg_coord%d\"%(p)] = wireimg_coord\n",
    "        wireimg_dict[\"wireimg_feat%d\"%(p)] = wireimg_feat\n",
    "\n",
    "\n",
    "    tripdata = kploader.triplet_v.at(0).get_all_triplet_data(True)\n",
    "    spandata = kploader.triplet_v.at(0).get_matchspan_array().astype(np.float32)\n",
    "    spacepoints = kploader.triplet_v.at(0).make_spacepoint_charge_array()\n",
    "\n",
    "    nfilled = c_int(0)\n",
    "    ntriplets = tripdata.shape[0]\n",
    "\n",
    "    kplabel_sigma = 5.0\n",
    "    TPCID = 0\n",
    "    CRYOID = 0\n",
    "    data = kploader.sample_data( ntriplets, nfilled, True, kplabel_sigma, TPCID, CRYOID )\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    #data.update(kpdata)\n",
    "    data.update(spacepoints)\n",
    "    data[\"truespan_t\"] = spandata\n",
    "\n",
    "    print(\"KeypointLoader returned dictionary with event data. KEYS: \")\n",
    "    print(data.keys())\n",
    "\n",
    "    voxeldata = voxelizer.get_full_voxel_labelset_dict( kploader )\n",
    "    # this returns a python list of dictionaries. \n",
    "    # the latter contains voxel data and labels for each TPC in the detector.\n",
    "    # (for detectors with more than one TPC. MicroBooNE has just one.)\n",
    "\n",
    "    # pick out one TPC's worth of data\n",
    "    vdata = voxeldata[0]\n",
    "#     print(vdata.keys())\n",
    "#     print(\"voxel coordinate tensor: \",vdata['voxcoord'].shape)\n",
    "#     print(\"voxel feature tensor: \",vdata['voxfeat'].shape)\n",
    "#     print(\"voxel ssnet  label tensor: \",vdata['ssnet_labels'].shape)\n",
    "#     print(\"voxel true/ghost labels: \",vdata['voxlabel'].shape)\n",
    "#     print(\"voxel array origin: \",vdata['voxorigin'].shape)\n",
    "\n",
    "#     print(\"unique ssnet labels in tensor: \",np.unique(vdata['ssnet_labels']))\n",
    "    # get the voxel arrays we need\n",
    "    voxcoord = vdata['voxcoord']\n",
    "    voxfeat  = vdata['voxfeat']\n",
    "    voxssnet = vdata['ssnet_labels']\n",
    "    # each voxel needs an ID number. We use the unrolled array position\n",
    "    # to calculate this, we need array strides for each dimension\n",
    "    strides = [ voxelizer.get_nvoxels()[0]*voxelizer.get_nvoxels()[1],\n",
    "                voxelizer.get_nvoxels()[2],\n",
    "                1]\n",
    "\n",
    "    \n",
    "    vset_uplane = larcv.VoxelSet() # save y-plane charge\n",
    "    vset_vplane = larcv.VoxelSet() # save y-plane charge\n",
    "    vset_yplane = larcv.VoxelSet() # save y-plane charge\n",
    "    vset_ssnet  = larcv.VoxelSet() # save particle labels\n",
    "\n",
    "    # some voxelset functions work best when voxels are added in sorted order (by ID number)\n",
    "    # so we do that first\n",
    "    idnums = []\n",
    "    id2index = {}\n",
    "    for n in range( voxcoord.shape[0] ):\n",
    "        # create a voxel: this consists of an ID and value.\n",
    "        # the ID is the array index\n",
    "        idnum = int( voxcoord[n,0]*strides[0] + voxcoord[n,1]*strides[1] + voxcoord[n,2]*strides[2] )\n",
    "        idnums.append(idnum)\n",
    "        id2index[idnum] = n\n",
    "\n",
    "    # sort the different idnumbers\n",
    "    idnums.sort()\n",
    "    for idnum in idnums:\n",
    "        # this format only allows us one feature: here filling with Y-plane values \n",
    "        vset_uplane.add( larcv.Voxel( idnum, voxfeat[id2index[idnum],0] ) )\n",
    "        vset_vplane.add( larcv.Voxel( idnum, voxfeat[id2index[idnum],1] ) )\n",
    "        vset_yplane.add( larcv.Voxel( idnum, voxfeat[id2index[idnum],2] ) )\n",
    "        ssnetlabel = int(voxssnet[id2index[idnum]])\n",
    "        # there needs to be come translation between our label definitions to lartpc_mlreco3d label definitions\n",
    "\n",
    "        mlrecolabel = larcv2mlreco[ssnetlabel]\n",
    "        vset_ssnet.add( larcv.Voxel(idnum, float(mlrecolabel) ))\n",
    "\n",
    "    # now we need the meta, that helps us go from array index to position in detector space\n",
    "    meta3d = larcv.Voxel3DMeta()\n",
    "    \"\"\"\n",
    "    inline void set(double xmin, double ymin, double zmin,\n",
    "                        double xmax, double ymax, double zmax,\n",
    "                        size_t xnum,size_t ynum,size_t znum,\n",
    "                        DistanceUnit_t unit=kUnitCM)\n",
    "    \"\"\"\n",
    "    meta3d.set( voxelizer.get_origin()[0], voxelizer.get_origin()[1], voxelizer.get_origin()[2],\n",
    "                voxelizer.get_origin()[0]+voxelizer.get_dim_len()[0],\n",
    "                voxelizer.get_origin()[1]+voxelizer.get_dim_len()[1],\n",
    "                voxelizer.get_origin()[2]+voxelizer.get_dim_len()[2],\n",
    "                voxelizer.get_nvoxels()[0], voxelizer.get_nvoxels()[1], voxelizer.get_nvoxels()[2] )\n",
    "\n",
    "\n",
    "    # we need an event container for the tensor. \n",
    "    # we get one from the IOManager so that is all setup to be saved to the root tree\n",
    "    # note the name of the containers is based on the lartpc_mlreco3d config 'config_uresnet_ppn.cfg'\n",
    "    #  * for charge data: \"pcluster\"\n",
    "    #  * for ssnet labels: \"pcluster_semantic\"\n",
    "    event_vox3d_uplane = out_larcv.get_data( larcv.kProductSparseTensor3D, \"pcluster_uplane\" )\n",
    "    event_vox3d_vplane = out_larcv.get_data( larcv.kProductSparseTensor3D, \"pcluster_vplane\" )\n",
    "    event_vox3d_yplane = out_larcv.get_data( larcv.kProductSparseTensor3D, \"pcluster_yplane\" )\n",
    "    event_vox3d_ssnet  = out_larcv.get_data( larcv.kProductSparseTensor3D, \"pcluster_semantic\" )\n",
    "    # add the data\n",
    "    event_vox3d_uplane.set( vset_uplane, meta3d )\n",
    "    event_vox3d_vplane.set( vset_vplane, meta3d )\n",
    "    event_vox3d_yplane.set( vset_yplane, meta3d )\n",
    "    event_vox3d_ssnet.set(  vset_ssnet,  meta3d )\n",
    "\n",
    "    # save the event to file\n",
    "    out_larcv.set_id(  0, 0, i) # set an arbitrary (run,subrun,event) index\n",
    "    out_larcv.save_entry()\n",
    "    \n",
    "    # tripletmaker.clear()\n",
    "        \n",
    "\n",
    "# finalize the file (properly close file)\n",
    "out_larcv.finalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We generate the TPC boundary lines for plotting and define useful defaults for our figures\n",
    "\n",
    "import lardly\n",
    "from lardly.detectoroutline import get_tpc_boundary_plot\n",
    "\n",
    "tpclines = get_tpc_boundary_plot()\n",
    "\n",
    "axis_template = {\n",
    "    \"showbackground\": True,\n",
    "    \"backgroundcolor\": \"rgba(10,10,10,0.1)\",\n",
    "    \"gridcolor\": \"rgb(10, 10, 10,0.2)\",\n",
    "    \"zerolinecolor\": \"rgb(10,10,10,0.4)\",\n",
    "}\n",
    "\n",
    "plot_layout = {\n",
    "    \"title\": \"\",\n",
    "    \"height\":800,\n",
    "    \"margin\": {\"t\": 0, \"b\": 0, \"l\": 0, \"r\": 0},\n",
    "    \"font\": {\"size\": 12, \"color\": \"black\"},\n",
    "    \"showlegend\": False,\n",
    "    \"plot_bgcolor\": \"white\",\n",
    "    \"paper_bgcolor\": \"white\",\n",
    "    \"scene\": {\n",
    "        \"xaxis\": axis_template,\n",
    "        \"yaxis\": axis_template,\n",
    "        \"zaxis\": axis_template,\n",
    "        \"aspectratio\": {\"x\": 1, \"y\": 1, \"z\": 3},\n",
    "        \"camera\": {\"eye\": {\"x\": 3, \"y\": 2, \"z\": 2},\n",
    "                   \"up\":dict(x=0, y=1, z=0)},\n",
    "        \"annotations\": [],\n",
    "    },\n",
    "}\n",
    "\n",
    "# PARTICLE LABEL COLORS\n",
    "# from larcv/core/DataFormat/DataFormatTypes.h\n",
    "#     kROIUnknown=0, ///< LArbys\n",
    "#     kROICosmic,    ///< Cosmics\n",
    "#     kROIBNB,       ///< BNB\n",
    "#     kROIEminus,    ///< Electron\n",
    "#     kROIGamma,     ///< Gamma\n",
    "#     kROIPizero,    ///< Pi0\n",
    "#     kROIMuminus,   ///< Muon\n",
    "#     kROIKminus,    ///< Kaon\n",
    "#     kROIPiminus,   ///< Charged Pion\n",
    "#     kROIProton,    ///< Proton\n",
    "#     kROITypeMax    ///< enum element counter\n",
    "ssnetcolor = {0:np.array((0,0,0)),     # kROIUnknown                                                                                                                                                   \n",
    "              1:np.array((255,0,0)),   # kROICosmic (not used)                                                                                                                                       \n",
    "              2:np.array((0,255,0)),   # kROIBNB (not used)                                                                                                                             \n",
    "              3:np.array((0,0,255)),   # kROIEminus (e-/e+)                                                                                                                                              \n",
    "              4:np.array((255,0,255)), # kROIGamma                                                                                                                                                 \n",
    "              5:np.array((0,255,255)), # kROIPizero                                                                                                                                            \n",
    "              6:np.array((255,255,0)), # kROImuminus (mu-/mu+)\n",
    "              7:np.array((123,300,10)),# kROIKminus (k+/k-)\n",
    "              8:np.array((204,204,255)), # kROIPiminus (pi+/pi-)\n",
    "              9:np.array((255, 165, 0))} # kProton\n",
    "\n",
    "kpcolors = {0:np.array((255,0,0)), # nu\n",
    "            1:np.array((0,255,0)), # track-start\n",
    "            2:np.array((0,0,255)), # track-end\n",
    "            3:np.array((255,255,0)), # shower\n",
    "            4:np.array((0,255,255)), # michel\n",
    "            5:np.array((255,0,255))} # delt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
